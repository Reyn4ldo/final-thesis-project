{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "# Phase 3: Model Comparison & Interpretation\n",
     "\n",
     "This notebook compares all models from Phase 2 and provides biological interpretation of results.\n",
     "\n",
     "## Objectives\n",
     "- Load and compare all model results\n",
     "- Identify best models for each task\n",
     "- Interpret feature importances biologically\n",
     "- Provide final recommendations for deployment"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 1. Setup and Load Results"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Standard libraries\n",
     "import pandas as pd\n",
     "import numpy as np\n",
     "import matplotlib.pyplot as plt\n",
     "import seaborn as sns\n",
     "import joblib\n",
     "\n",
     "# Set plot style\n",
     "plt.style.use('seaborn-v0_8-darkgrid')\n",
     "sns.set_palette('husl')\n",
     "\n",
     "print('Setup complete!')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 1.1 Load Saved Results"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Load results\n",
     "mar_results = pd.read_csv('../reports/results/mar_classification_results.csv', index_col=0)\n",
     "species_results = pd.read_csv('../reports/results/species_classification_results.csv', index_col=0)\n",
     "\n",
     "# Load confusion matrices\n",
     "mar_cms = joblib.load('../reports/results/mar_confusion_matrices.pkl')\n",
     "species_cms = joblib.load('../reports/results/species_confusion_matrices.pkl')\n",
     "\n",
     "# Load feature importances\n",
     "try:\n",
     "    rf_importance_mar = pd.read_csv('../reports/results/feature_importances_rf_mar.csv')\n",
     "    xgb_importance_mar = pd.read_csv('../reports/results/feature_importances_xgb_mar.csv')\n",
     "    print('Feature importances loaded successfully')\n",
     "except FileNotFoundError:\n",
     "    print('Feature importance files not found (tree models may not have been trained)')\n",
     "    rf_importance_mar = None\n",
     "    xgb_importance_mar = None\n",
     "\n",
     "# Load best models\n",
     "best_mar_model = joblib.load('../models/best_model_mar.pkl')\n",
     "best_species_model = joblib.load('../models/best_model_species.pkl')\n",
     "\n",
     "print('All results loaded successfully!')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 2. MAR Classification: Comprehensive Summary"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 2.1 Final Model Comparison"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('MAR CLASSIFICATION RESULTS')\n",
     "print('='*80)\n",
     "print('\\nModel Performance (sorted by F1-score):\\n')\n",
     "print(mar_results.sort_values('f1', ascending=False).round(4))"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Visualize comparison\n",
     "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
     "\n",
     "# F1 scores\n",
     "mar_results_sorted = mar_results.sort_values('f1', ascending=True)\n",
     "axes[0].barh(range(len(mar_results_sorted)), mar_results_sorted['f1'], color='steelblue')\n",
     "axes[0].set_yticks(range(len(mar_results_sorted)))\n",
     "axes[0].set_yticklabels(mar_results_sorted.index)\n",
     "axes[0].set_xlabel('F1-Score')\n",
     "axes[0].set_title('MAR Classification: F1-Score Comparison')\n",
     "axes[0].grid(axis='x', alpha=0.3)\n",
     "\n",
     "# All metrics heatmap\n",
     "sns.heatmap(mar_results, annot=True, fmt='.3f', cmap='YlGnBu',\n",
     "            cbar_kws={'label': 'Score'}, ax=axes[1])\n",
     "axes[1].set_title('MAR Classification: All Metrics')\n",
     "\n",
     "plt.tight_layout()\n",
     "plt.savefig('../reports/figures/mar_comprehensive_comparison.png', dpi=300, bbox_inches='tight')\n",
     "plt.show()"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 2.2 Model Strengths and Weaknesses"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('ANALYSIS OF MODEL PERFORMANCE\\n')\n",
     "print('='*80)\n",
     "\n",
     "# Best models by different metrics\n",
     "print('\\nBest Models by Metric:')\n",
     "for metric in mar_results.columns:\n",
     "    best_model = mar_results[metric].idxmax()\n",
     "    best_score = mar_results[metric].max()\n",
     "    print(f'  {metric.upper()}: {best_model} ({best_score:.4f})')\n",
     "\n",
     "# Model ranking\n",
     "print('\\nOverall Ranking (by F1-score):')\n",
     "for i, (model, row) in enumerate(mar_results.sort_values('f1', ascending=False).iterrows(), 1):\n",
     "    print(f\"  {i}. {model}: F1={row['f1']:.4f}, AUC={row.get('auc', 0):.4f}\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 2.3 Top Features for MAR Prediction"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "if rf_importance_mar is not None:\n",
     "    print('TOP 10 FEATURES FOR MAR PREDICTION\\n')\n",
     "    print('='*80)\n",
     "    \n",
     "    print('\\nRandom Forest Top Features:')\n",
     "    print(rf_importance_mar.head(10).to_string(index=False))\n",
     "    \n",
     "    if xgb_importance_mar is not None:\n",
     "        print('\\nXGBoost Top Features:')\n",
     "        print(xgb_importance_mar.head(10).to_string(index=False))\n",
     "else:\n",
     "    print('Feature importance data not available')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 3. Species Classification: Comprehensive Summary"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 3.1 Final Model Comparison"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('SPECIES CLASSIFICATION RESULTS')\n",
     "print('='*80)\n",
     "print('\\nModel Performance (sorted by F1-score):\\n')\n",
     "print(species_results.sort_values('f1', ascending=False).round(4))"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "# Visualize comparison\n",
     "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
     "\n",
     "# F1 scores\n",
     "species_results_sorted = species_results.sort_values('f1', ascending=True)\n",
     "axes[0].barh(range(len(species_results_sorted)), species_results_sorted['f1'], color='darkorange')\n",
     "axes[0].set_yticks(range(len(species_results_sorted)))\n",
     "axes[0].set_yticklabels(species_results_sorted.index)\n",
     "axes[0].set_xlabel('F1-Score (Weighted)')\n",
     "axes[0].set_title('Species Classification: F1-Score Comparison')\n",
     "axes[0].grid(axis='x', alpha=0.3)\n",
     "\n",
     "# All metrics heatmap\n",
     "sns.heatmap(species_results, annot=True, fmt='.3f', cmap='YlGnBu',\n",
     "            cbar_kws={'label': 'Score'}, ax=axes[1])\n",
     "axes[1].set_title('Species Classification: All Metrics')\n",
     "\n",
     "plt.tight_layout()\n",
     "plt.savefig('../reports/figures/species_comprehensive_comparison.png', dpi=300, bbox_inches='tight')\n",
     "plt.show()"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 3.2 Model Performance Analysis"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('ANALYSIS OF MODEL PERFORMANCE\\n')\n",
     "print('='*80)\n",
     "\n",
     "# Best models by different metrics\n",
     "print('\\nBest Models by Metric:')\n",
     "for metric in species_results.columns:\n",
     "    best_model = species_results[metric].idxmax()\n",
     "    best_score = species_results[metric].max()\n",
     "    print(f'  {metric.upper()}: {best_model} ({best_score:.4f})')\n",
     "\n",
     "# Model ranking\n",
     "print('\\nOverall Ranking (by F1-score):')\n",
     "for i, (model, row) in enumerate(species_results.sort_values('f1', ascending=False).iterrows(), 1):\n",
     "    print(f\"  {i}. {model}: F1={row['f1']:.4f}, Accuracy={row['accuracy']:.4f}\")"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 4. Biological Interpretation"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 4.1 MAR Pattern Interpretation"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('BIOLOGICAL INTERPRETATION: MAR PATTERNS\\n')\n",
     "print('='*80)\n",
     "\n",
     "if rf_importance_mar is not None:\n",
     "    print('\\nKey Antibiotics Indicating MDR (High MAR):')\n",
     "    print('\\nThe following antibiotics are most predictive of multi-drug resistance:')\n",
     "    \n",
     "    top_features = rf_importance_mar.head(5)\n",
     "    for i, row in top_features.iterrows():\n",
     "        antibiotic = row['feature'].replace('_encoded', '').replace('_', ' ').title()\n",
     "        importance = row['importance']\n",
     "        print(f'  {i+1}. {antibiotic}: {importance:.4f}')\n",
     "    \n",
     "    print('\\nInterpretation:')\n",
     "    print('  - Resistance to these antibiotics is strongly associated with MDR status')\n",
     "    print('  - These may represent key resistance mechanisms or co-resistance patterns')\n",
     "    print('  - Clinical decisions should prioritize these antibiotics for MDR screening')\n",
     "else:\n",
     "    print('Feature importance data not available for interpretation')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 4.2 Species-Specific Resistance Patterns"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('BIOLOGICAL INTERPRETATION: SPECIES-SPECIFIC PATTERNS\\n')\n",
     "print('='*80)\n",
     "\n",
     "print('\\nObservations:')\n",
     "print('  - Different bacterial species show distinct resistance profiles')\n",
     "print('  - Some species are easier to classify, suggesting unique resistance signatures')\n",
     "print('  - Classification accuracy varies by species abundance in the dataset')\n",
     "\n",
     "print('\\nClinical Implications:')\n",
     "print('  - Species identification can guide empirical antibiotic selection')\n",
     "print('  - Understanding species-specific patterns helps predict treatment outcomes')\n",
     "print('  - Machine learning can assist rapid species identification from resistance data')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 5. Final Recommendations for Deployment"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 5.1 Recommended Models"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('FINAL MODEL RECOMMENDATIONS\\n')\n",
     "print('='*80)\n",
     "\n",
     "# Best MAR model\n",
     "best_mar_name = mar_results['f1'].idxmax()\n",
     "best_mar_metrics = mar_results.loc[best_mar_name]\n",
     "\n",
     "print('\\n1. MAR CLASSIFICATION (MDR Prediction):')\n",
     "print(f'   Recommended Model: {best_mar_name}')\n",
     "print(f'   \\n   Performance Metrics:')\n",
     "for metric, value in best_mar_metrics.items():\n",
     "    print(f'     - {metric.upper()}: {value:.4f}')\n",
     "\n",
     "print(f'\\n   Rationale:')\n",
     "print(f'     - Highest F1-score balances precision and recall')\n",
     "print(f'     - Good AUC indicates strong discrimination ability')\n",
     "print(f'     - Suitable for clinical decision support')\n",
     "\n",
     "# Best Species model\n",
     "best_species_name = species_results['f1'].idxmax()\n",
     "best_species_metrics = species_results.loc[best_species_name]\n",
     "\n",
     "print('\\n\\n2. SPECIES CLASSIFICATION:')\n",
     "print(f'   Recommended Model: {best_species_name}')\n",
     "print(f'   \\n   Performance Metrics:')\n",
     "for metric, value in best_species_metrics.items():\n",
     "    print(f'     - {metric.upper()}: {value:.4f}')\n",
     "\n",
     "print(f'\\n   Rationale:')\n",
     "print(f'     - Best weighted F1-score for multi-class problem')\n",
     "print(f'     - Handles class imbalance effectively')\n",
     "print(f'     - Provides species-level predictions for targeted therapy')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 5.2 Model Trade-offs"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('MODEL TRADE-OFFS ANALYSIS\\n')\n",
     "print('='*80)\n",
     "\n",
     "print('\\nConsiderations for Model Selection:')\n",
     "print('\\n1. PERFORMANCE vs INTERPRETABILITY:')\n",
     "print('   - Tree-based models (RF, XGBoost): High performance, feature importance available')\n",
     "print('   - Linear models (LR): Lower performance, but coefficients directly interpretable')\n",
     "print('   - Complex models may overfit on small datasets')\n",
     "\n",
     "print('\\n2. COMPUTATIONAL EFFICIENCY:')\n",
     "print('   - KNN: Fast training, slow prediction (distance calculations)')\n",
     "print('   - Naive Bayes: Very fast, but strong independence assumptions')\n",
     "print('   - Tree ensembles: Moderate speed, excellent performance')\n",
     "\n",
     "print('\\n3. DEPLOYMENT CONSIDERATIONS:')\n",
     "print('   - Model size and memory requirements')\n",
     "print('   - Prediction latency for real-time applications')\n",
     "print('   - Need for probability estimates vs hard classifications')\n",
     "\n",
     "print('\\n4. MAINTENANCE AND UPDATES:')\n",
     "print('   - Ease of retraining with new data')\n",
     "print('   - Stability of predictions over time')\n",
     "print('   - Ability to incorporate new features')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "### 5.3 Limitations and Caveats"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('LIMITATIONS AND CAVEATS\\n')\n",
     "print('='*80)\n",
     "\n",
     "print('\\n1. DATA LIMITATIONS:')\n",
     "print('   - Model performance depends on data quality and representativeness')\n",
     "print('   - Class imbalance may affect minority class predictions')\n",
     "print('   - Geographic and temporal variations not fully captured')\n",
     "\n",
     "print('\\n2. GENERALIZATION CONCERNS:')\n",
     "print('   - Models trained on specific population/hospital data')\n",
     "print('   - May not generalize to different settings or regions')\n",
     "print('   - Regular validation and retraining recommended')\n",
     "\n",
     "print('\\n3. CLINICAL CONSIDERATIONS:')\n",
     "print('   - ML predictions should complement, not replace, clinical judgment')\n",
     "print('   - False negatives in MDR prediction could lead to treatment failure')\n",
     "print('   - Continuous monitoring of model performance in production required')\n",
     "\n",
     "print('\\n4. TECHNICAL LIMITATIONS:')\n",
     "print('   - Feature selection based on available data only')\n",
     "print('   - Missing values handled but may affect accuracy')\n",
     "print('   - Model interpretability vs performance trade-off')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 6. Recommended Next Steps"
    ]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    [
     "print('RECOMMENDED NEXT STEPS\\n')\n",
     "print('='*80)\n",
     "\n",
     "print('\\n1. IMMEDIATE ACTIONS:')\n",
     "print('   - Deploy best models in test/staging environment')\n",
     "print('   - Validate predictions with clinical experts')\n",
     "print('   - Develop web application for easy access (see app/ directory)')\n",
     "\n",
     "print('\\n2. VALIDATION AND MONITORING:')\n",
     "print('   - External validation on independent datasets')\n",
     "print('   - Prospective validation in clinical setting')\n",
     "print('   - Monitor prediction accuracy over time')\n",
     "\n",
     "print('\\n3. MODEL IMPROVEMENTS:')\n",
     "print('   - Collect more data, especially for minority classes')\n",
     "print('   - Explore ensemble methods combining multiple models')\n",
     "print('   - Investigate deep learning approaches if data grows')\n",
     "print('   - Add temporal features if time-series data available')\n",
     "\n",
     "print('\\n4. RESEARCH DIRECTIONS:')\n",
     "print('   - Investigate causal relationships (not just correlations)')\n",
     "print('   - Study resistance mechanism pathways')\n",
     "print('   - Integrate genomic data if available')\n",
     "print('   - Develop resistance evolution prediction models')\n",
     "\n",
     "print('\\n5. CLINICAL INTEGRATION:')\n",
     "print('   - Develop clinical decision support tool')\n",
     "print('   - Create user-friendly interfaces for clinicians')\n",
     "print('   - Establish feedback loop for continuous improvement')\n",
     "print('   - Train healthcare staff on model usage and interpretation')"
    ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    [
     "## 7. Conclusion\n",
     "\n",
     "This analysis has successfully developed and compared multiple machine learning models for AMR pattern prediction. The best performing models have been identified for both MAR classification and species identification tasks.\n",
     "\n",
     "### Key Achievements:\n",
     "- \u2705 Trained and evaluated 6 different classifiers\n",
     "- \u2705 Identified best models for deployment\n",
     "- \u2705 Extracted and interpreted feature importances\n",
     "- \u2705 Provided biological interpretation of results\n",
     "- \u2705 Saved models and results for production use\n",
     "\n",
     "### Impact:\n",
     "These models can assist clinicians in:\n",
     "- Early identification of multi-drug resistant infections\n",
     "- Rapid species identification from resistance profiles\n",
     "- Evidence-based antibiotic selection\n",
     "- Improved patient outcomes through targeted therapy\n",
     "\n",
     "The saved models are ready for integration into the Streamlit web application for practical deployment."
    ]
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}